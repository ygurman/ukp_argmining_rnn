# model parameters
d_word_embd: 100
d_pos_embd: 25
n_lstm_layers: 1
d_h1: 100
word_voc_size: 400226
pos_voc_size: 41
ac_tagset_size: 7
pretraind_embd_layer_path: /home/yochay/ukp_argmining_rnn/data/vocabularies/combined_word_voc_embdLayer.pcl
batch_size: 1
# training and optimization parameters
n_epochs: 100
clip_threshold: 10
learning_rate: 1e-3
weight_decay: 0
# general parameters
models_dir: /home/yochay/ukp_argmining_rnn/models